# RAG System Guide

## üéØ T·ªïng quan

H·ªá th·ªëng RAG (Retrieval-Augmented Generation) cho ph√©p AI assistant tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n t√†i li·ªáu ƒë√£ ƒë∆∞·ª£c upload v√† embedding trong vector database. Lu·ªìng ho·∫°t ƒë·ªông: **user query ‚Üí RAG [Vector search, Hybrid search] ‚Üí LLM**.

## ‚úÖ T√≠nh nƒÉng

### 1. **Vector Search**
- **Dense Vector Search**: S·ª≠ d·ª•ng cosine similarity v·ªõi 1024-dim embeddings
- **Sparse Vector Search**: S·ª≠ d·ª•ng BM25 cho keyword matching
- **Hybrid Search**: K·∫øt h·ª£p c·∫£ dense v√† sparse search v·ªõi weighted scoring

### 2. **Context Building**
- L·ªçc v√† rank documents theo relevance score
- Format context t·ªëi ∆∞u cho LLM consumption
- Gi·ªõi h·∫°n context length ƒë·ªÉ tr√°nh token limit
- Source attribution v√† metadata tracking

### 3. **RAG Agent**
- K·∫ø th·ª´a BaseAgent architecture
- T√≠ch h·ª£p v·ªõi existing LLM providers (Gemini, OpenAI)
- User isolation v√† error handling
- Conversation context support

## üìÅ C·∫•u tr√∫c Files

```
src/RAG/
‚îú‚îÄ‚îÄ __init__.py              # Package initialization
‚îú‚îÄ‚îÄ vector_search.py         # Vector search service
‚îú‚îÄ‚îÄ context_builder.py       # Context building logic
‚îî‚îÄ‚îÄ rag_agent.py            # Main RAG agent

examples/
‚îî‚îÄ‚îÄ rag_usage_example.py     # Usage examples v√† tests

docs/
‚îî‚îÄ‚îÄ RAG_SYSTEM_GUIDE.md     # This guide
```

## üöÄ C√°ch s·ª≠ d·ª•ng

### 1. **Basic RAG Agent Usage**

```python
from src.RAG import RAGAgent
from src.llms.llm_factory import LLMFactory
from src.config.settings import config
from src.core.types import AgentState

# Initialize RAG agent
llm_factory = LLMFactory(config.llm)
rag_agent = RAGAgent(
    llm_factory=llm_factory,
    search_type="hybrid",  # "dense", "sparse", or "hybrid"
    max_context_length=4000
)

# Create query state
state = AgentState(
    input="What is machine learning?",
    user_id="user123",
    conversation_context=[],
    # ... other fields
)

# Process with RAG
result = rag_agent.process(state)
print(result["final_result"])  # AI response with context
print(result["rag_metadata"])  # Search metadata
```

### 2. **Vector Search Only**

```python
from src.RAG import VectorSearchService

# Initialize search service
search_service = VectorSearchService()

# Perform different types of search
dense_results = search_service.search_dense("machine learning", "user123", limit=5)
sparse_results = search_service.search_sparse("python programming", "user123", limit=5)
hybrid_results = search_service.search_hybrid("data science", "user123", limit=5)

# Unified search interface
results = search_service.search(
    query="AI algorithms",
    user_id="user123",
    search_type="hybrid",
    limit=10
)
```

### 3. **Context Building**

```python
from src.RAG import ContextBuilder

# Initialize context builder
context_builder = ContextBuilder(
    max_context_length=3000,
    min_relevance_score=0.3,
    max_documents=5
)

# Build context from search results
context_data = context_builder.build_context(search_results, query="AI question")

print(f"Documents: {context_data['total_documents']}")
print(f"Context: {context_data['context']}")
print(f"Sources: {context_data['sources']}")
```

## üîß Configuration

### Environment Variables
```env
# Qdrant Configuration (already configured)
QDRANT_CLOUD_API_KEY=your_api_key
QDRANT_URL=https://your-cluster.qdrant.io
QDRANT_COLLECTION=agent_data

# LLM Configuration (already configured)
LLM_PROVIDER=gemini
LLM_MODEL=gemini-2.0-flash
LLM_TEMPERATURE=0.2
```

### RAG Agent Parameters
```python
RAGAgent(
    llm_factory=llm_factory,
    search_type="hybrid",        # Search strategy
    max_context_length=4000,     # Max context chars
    max_search_results=10        # Max search results
)
```

### Context Builder Parameters
```python
ContextBuilder(
    max_context_length=4000,     # Max context chars
    min_relevance_score=0.3,     # Min score to include
    max_documents=5              # Max documents to include
)
```

## üîÑ Integration v·ªõi Existing System

### 1. **V·ªõi Simple Graph**
```python
from src.core.simple_graph import process_rag_node

# RAG node ƒë√£ ƒë∆∞·ª£c th√™m v√†o simple_graph.py
# S·ª≠ d·ª•ng process_rag_node thay v√¨ process_conversation_node
```

### 2. **V·ªõi Auth Server**
```python
# Trong auth_server.py, c√≥ th·ªÉ th√™m RAG endpoint
@app.post("/api/rag/query")
async def rag_query(request: dict):
    user_id = request.get("user_id")
    query = request.get("query")
    
    # Create RAG agent
    rag_agent = create_rag_agent()
    
    # Process query
    state = AgentState(input=query, user_id=user_id, ...)
    result = rag_agent.process(state)
    
    return result
```

## üìä Search Types Comparison

| Search Type | Strengths | Use Cases |
|-------------|-----------|-----------|
| **Dense** | Semantic similarity, context understanding | Conceptual questions, similar meaning |
| **Sparse** | Exact keyword matching, fast | Specific terms, names, technical keywords |
| **Hybrid** | Best of both worlds, balanced results | General purpose, most recommended |

## üéØ Best Practices

### 1. **Search Strategy**
- S·ª≠ d·ª•ng **hybrid search** cho most cases
- D√πng **dense search** cho conceptual questions
- D√πng **sparse search** cho exact keyword matching

### 2. **Context Management**
- Gi·ªõi h·∫°n context length ƒë·ªÉ tr√°nh token limits
- Filter documents v·ªõi min relevance score
- Provide source attribution trong responses

### 3. **Error Handling**
- Graceful fallback khi RAG components unavailable
- User-friendly error messages
- Maintain conversation flow even khi search fails

### 4. **Performance**
- Cache search results n·∫øu c·∫ßn
- Optimize embedding dimensions
- Monitor search latency

## üß™ Testing

### Run Example Tests
```bash
cd /path/to/multi_agents
python examples/rag_usage_example.py
```

### Test Components
```python
# Test vector search
python -c "from examples.rag_usage_example import test_vector_search; test_vector_search()"

# Test context builder
python -c "from examples.rag_usage_example import test_context_builder; test_context_builder()"

# Test RAG agent
python -c "from examples.rag_usage_example import test_rag_agent; test_rag_agent()"
```

## üîç Troubleshooting

### Common Issues

1. **"Qdrant infrastructure not available"**
   - Check QDRANT_CLOUD_API_KEY v√† QDRANT_URL trong .env
   - Verify Qdrant connection

2. **"No search results found"**
   - Check if user has uploaded documents
   - Verify user_id isolation
   - Try different search types

3. **"Context too long"**
   - Reduce max_context_length
   - Increase min_relevance_score
   - Reduce max_documents

4. **"RAG agent not available"**
   - Check if all dependencies installed
   - Verify import paths
   - Fallback to regular conversation agent

## üìà Future Enhancements

- [ ] **Advanced Reranking**: Implement cross-encoder reranking
- [ ] **Query Expansion**: Auto-expand queries for better recall
- [ ] **Caching**: Cache search results v√† embeddings
- [ ] **Analytics**: Track search performance v√† user satisfaction
- [ ] **Multi-modal**: Support image v√† audio documents
